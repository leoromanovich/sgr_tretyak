# Schema Guided Reasoning (SGR) Cheatsheet

Этот проект целиком строится на Schema Guided Reasoning: мы заранее описываем целевые структуры данных (через Pydantic), передаём их LLM и требуем строгое соответствие схеме. Ниже — набор правил, который позволит агенту быстро начать или продолжить разработку в таком стиле.

## 1. Общая идея
- **Сначала структура, потом промпт.** Любая новая задача начинается с описания целевой Pydantic‑модели в `src/models.py` (или рядом). Модель сразу выступает единственным источником правды для схемы SGR.
- **LLM как чистый парсер.** Вызовы через `chat_sgr_parse*` принимают `response_format=json_schema` и валидируют JSON через Pydantic. Никаких вольностей: если модель не укладывается в схему — считаем ответ невалидным и повторяем/чиним.
- **Весь пайплайн идёт через кэш.** Результаты каждого шага (метаданные, кандидаты, кластеры…) сохраняем в `cache/*.jsonl` или аналогичные файлы. Это нужно для повторов и отладки без повторных запросов к LLM.

## 2. Как проектировать схему
1. **Определи сущности.** Пример: `NoteMetadata`, `PersonLocal`, `PersonLocalNormalized`, `PersonCandidate`, `PersonMatchDecision`, `GlobalPerson`. Каждый шаг пайплайна оперирует своим типом.
2. **Добавляй подробные Field-декларации.** Это не только помогает команде, но и попадает в JSON Schema → лучшее качество ответов.
3. **Закладывай валидацию.** Пример: `confidence: float = Field(..., ge=0.0, le=1.0)` гарантирует, что модель вернёт значение 0–1.
4. **Связывай схемы между собой.** Если новая модель опирается на существующую (`PersonLocalNormalized(PersonLocal)`), наследуйся — LLM сразу видит полную структуру.
5. **Максимум определённости.** Если поле можно вывести детерминированно (например, `note_id`), заполняй его заранее до вызова LLM и не проси модель угадывать.

## 3. Как строить запрос
1. **System-промпт = правила игры.** Опиши задачу, ограничения, запреты на «придумки». В примерах в `src/tools/note_metadata.py` мы явно запрещаем использовать внешние знания и прописываем критерии заполнения полей.
2. **User-промпт = конкретный ввод.** Вставляй исходный текст/данные и короткую инструкцию. Часто полезно добавлять сигналы вроде `/no_think`, чтобы модель не углублялась, если это поддерживается сервером.
3. **Температура ≈ 0.** SGR — детерминированная история. Любые творческие скачки только мешают.
4. **Токены с запасом.** `max_tokens` ставим с запасом, чтобы JSON целиком поместился.
5. **Повторное использование моделей.** Если этап уже реализован (`note_metadata`, `people_extractor`, `name_normalizer`), смотри готовые промпты в `src/tools/*.py` и копируй структуру.

## 4. Как вызывать SGR
1. **Синхронно:** `chat_sgr_parse(messages, model_cls=NoteMetadataResponse, schema_name="note_metadata")`.
2. **Асинхронно:** `await chat_sgr_parse_async(...)` — с лимитом по семафору (`LLM_CONCURRENCY_LIMIT` в `llm_client.py`).
3. **Schema-name.** Передавай человекочитаемое имя (`schema_name="people_extractor"`). Оно попадёт в логи и поможет отличать вызовы.
4. **Ответ = Pydantic-модель.** Получаем уже валидированный объект; дальше его можно сериализовать `model_dump()`, складывать в JSONL и пр.
5. **Повторы / ошибки.** Если `RuntimeError` про JSON/parsing — это повод улучшить схему или промпт. Никогда не глотаем исключение молча.

## 5. Разработка и отладка
- **Включай трассировку.** Переменная `SGR_LOGGING=DEBUG` заставит `llm_client` писать подробные логи в `log_tracing/` (сообщения, schema_name, сырой ответ).
- **Делай линейный прогон.** Любой новый инструмент сначала тестируем на одной заметке, сохраняем результат в `cache/…`, проверяем руками и только потом запускаем по батчу.
- **Разрешай неоднозначности.** Если модель должна возвращать разные статусы (`same_person | different_person | unknown`), не пытайся вшить бизнес-логку в одно поле. Всегда лучше отдельное перечисление.
- **Добавляй тесты.** Даже если шаг завязан на LLM, окружай его детерминированными проверками (как `tests/test_cluster_people.py` для эвристик) и заглушками.
- **Не смешивай контексты.** Один вызов SGR = одна задача. Не проси модель одновременно писать заметку и извлекать метаданные: проще два инструмента.

## 6. Типовой цикл разработки SGR-инструмента
1. **Опиши модель.** Добавь Pydantic-класс в `src/models.py` (с docstring и Field‑описаниями).
2. **Напиши тул.** Создай `src/tools/<name>.py` с функциями `*_async` и синхронным враппером; подключи `llm_client`.
3. **Кэшируй результат.** Определи, в какой файл писать (например, `cache/persons_local.jsonl`). Используй `orjson` для потоковой записи.
4. **Интегрируй в CLI.** В `src/orchestrator.py` добавь команду, которая берёт данные из предыдущего шага, вызывает новый тул и пишет результат.
5. **Документируй.** Любой новый инструмент и его JSON-формат должен быть описан либо в `SGR.md`, либо в README/RULES.

## 7. Принципы качества
- **Детерминированность.** Чем меньше свободы у модели, тем больше пользы. Фиксируем temperature, структуру, порядок шагов.
- **Прозрачность.** Каждое поле должно быть обосновано текстом. Если модель не уверена — возвращает `None`/пустой список, но не придумывает.
- **Модульность.** Каждый тул решает одну задачу: извлечь метаданные, выделить людей, нормализовать имя, сопоставить кандидатов, сгенерировать заметку. Это облегчает отладку.
- **Идемпотентность.** Все команды запускаются повторно без побочных эффектов. Файлы в `cache/` и `data/obsidian/` можно перегенерировать теми же именами.
- **Логи и статистика.** Любой массовый шаг должен печатать прогресс через `rich`/`tqdm`, чтобы понимать, сколько вызовов ушло в SGR и где возможны сбои.

Придерживаясь этих правил, агент быстро сориентируется в пайплайне и будет добавлять новые SGR-шаги без неожиданностей. Если нужно больше примеров — смотри `src/tools/note_metadata.py`, `src/tools/person_note_generator.py`, `src/tools/note_linker.py`, `llm_client.py` и `RULES.md`.
